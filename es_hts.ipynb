{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecd6601c-d079-4851-ac4c-ffa38a63be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bc4f122-4587-4f51-a275-907d047f6b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec0e28a7-4655-4db5-999f-c2925623b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Elasticsearch\n",
    "es = Elasticsearch(\n",
    "    \"https://ibm_cloud_0b9024c7_cbb7_4a9b_85d8_b10002602b8b:e24967c05fafe955711c7b783c4f647cb16f02f157fd71cd4393835d0c6e82cd@1cfae122-8d99-40f8-b662-2f582f6bead9.c5kmhkid0ujpmrucb800.databases.appdomain.cloud:31244\",\n",
    "    verify_certs=False,\n",
    "    ca_certs=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35b79029-1372-4861-a63a-c0d72eff7724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ingestion pipeline in Elasticsearch\n",
    "pipeline_id = \"fs_kb_web_crawl_pipeline\"\n",
    "pipeline_body = {\n",
    "    \"description\": \"Pipeline to process crawled web data\",\n",
    "    \"processors\": [\n",
    "        {\n",
    "            \"remove\": {\n",
    "                \"field\": \"html\"  # Remove raw HTML content after processing\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"set\": {\n",
    "                \"field\": \"timestamp\",\n",
    "                \"value\": \"{{_ingest.timestamp}}\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e178f6db-cae5-42d8-a5b5-81e383543292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline 'fs_kb_web_crawl_pipeline' created.\n"
     ]
    }
   ],
   "source": [
    "# Create or update the pipeline\n",
    "if not es.ingest.get_pipeline(id=pipeline_id, ignore=[404]):\n",
    "    es.ingest.put_pipeline(id=pipeline_id, body=pipeline_body)\n",
    "    print(f\"Pipeline '{pipeline_id}' created.\")\n",
    "else:\n",
    "    es.ingest.put_pipeline(id=pipeline_id, body=pipeline_body)\n",
    "    print(f\"Pipeline '{pipeline_id}' updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aca2990c-214b-46d0-9c89-8e75ec6bcc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = '8nmVTUPD8kk4Omyl0t42:X'\n",
    "password = 'Admin@123'\n",
    "hostname = 'https://koresolutionssupport.freshservice.com/support/solutions/folders/15000044135'\n",
    "\n",
    "session = requests.Session()\n",
    "session.auth = (user, password)\n",
    "\n",
    "auth = session.post(hostname)\n",
    "#response = session.get('https://' + hostname + '/rest/applications')\n",
    "\n",
    "# Function to crawl a webpage and extract content\n",
    "def crawl_page(url):\n",
    "    try:\n",
    "        import requests\n",
    "        response = requests.get(url, auth=(user, password))\n",
    "        print(f'resp:{response}')\n",
    "        #response = requests.get(url)\n",
    "        response.raise_for_status()  # Check for request errors\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # Extract title, main content, and metadata\n",
    "        title = soup.title.string if soup.title else \"No Title\"\n",
    "        content = ' '.join([p.get_text() for p in soup.find_all(\"p\")])\n",
    "        \n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"title\": title,\n",
    "            \"content\": content,\n",
    "            \"html\": response.text  # Include raw HTML for further parsing if needed\n",
    "        }\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error crawling {url}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96775904-d1d5-4955-8056-2bea148a8dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp:<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# URLs to crawl\n",
    "urls = [\n",
    "    \"https://koresolutionssupport.freshservice.com/support/solutions/folders/15000044135\"#/15000006276-teamviewer-qs-remote-support-software\"\n",
    "    #\"https://example.com\",\n",
    "    #\"https://example.org\",\n",
    "    # Add more URLs here\n",
    "]\n",
    "\n",
    "# Crawl each URL and prepare for ingestion\n",
    "documents = []\n",
    "for url in urls:\n",
    "    data = crawl_page(url)\n",
    "    if data:\n",
    "        documents.append({\n",
    "            \"_index\": \"fs_kb_web_crawl_data\",\n",
    "            \"_op_type\": \"index\",\n",
    "            \"_source\": data,\n",
    "            \"pipeline\": pipeline_id\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b6e500c-9a1f-4f88-8d12-8d67af9ea7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_index': 'fs_kb_web_crawl_data',\n",
       "  '_op_type': 'index',\n",
       "  '_source': {'url': 'https://koresolutionssupport.freshservice.com/support/solutions/folders/15000044135',\n",
       "   'title': 'Freshworks',\n",
       "   'content': '',\n",
       "   'html': '<!doctype html><html lang=\"en\"><head><meta charset=\"utf-8\"><meta name=\"viewport\" content=\"width=device-width,initial-scale=1,shrink-to-fit=no\"><meta name=\"theme-color\" content=\"#000000\"><meta name=\"robots\" content=\"noindex\"><link rel=\"shortcut icon\" href=\"/api/v2/organisation/-/image?variant=ORIGINAL&entity_type=ORG_FAVICON\"><title>Freshworks</title><script type=\"text/javascript\" src=\"https://www.recaptcha.net/recaptcha/api.js\"></script><script>parcelRequire=function(e,t,n,i){var r,s=\"function\"==typeof parcelRequire&&parcelRequire,o=\"function\"==typeof require&&require;function a(n,i){if(!t[n]){if(!e[n]){var r=\"function\"==typeof parcelRequire&&parcelRequire;if(!i&&r)return r(n,!0);if(s)return s(n,!0);if(o&&\"string\"==typeof n)return o(n);var c=new Error(\"Cannot find module \\'\"+n+\"\\'\");throw c.code=\"MODULE_NOT_FOUND\",c}l.resolve=function(t){return e[n][1][t]||t},l.cache={};var u=t[n]=new a.Module(n);e[n][0].call(u.exports,l,u,u.exports,this)}return t[n].exports;function l(e){return a(l.resolve(e))}}a.isParcelRequire=!0,a.Module=function(e){this.id=e,this.bundle=a,this.exports={}},a.modules=e,a.cache=t,a.parent=s,a.register=function(t,n){e[t]=[function(e,t){t.exports=n},{}]};for(var c=0;c<n.length;c++)try{a(n[c])}catch(e){r||(r=e)}if(n.length){var u=a(n[n.length-1]);\"object\"==typeof exports&&\"undefined\"!=typeof module?module.exports=u:\"function\"==typeof define&&define.amd&&define((function(){return u}))}if(parcelRequire=a,r)throw r;return a}({b2lR:[function(e,t,n){\"use strict\";Object.defineProperty(n,\"__esModule\",{value:!0}),n.default=void 0;var i=function(e){var t=e.inlineScript,n=e.src,i=e.onload,r=e.defer,s=document.createElement(\"script\");if(t){var o=document.createTextNode(t);s.appendChild(o)}else s.onload=i,s.src=n,s.defer=r;document.getElementsByTagName(\"head\")[0].appendChild(s)};n.default=i},{}],ZV6f:[function(e,t,n){\"use strict\";Object.defineProperty(n,\"__esModule\",{value:!0}),n.default=function(){for(var e={},t=function(t){for(var n in t)Object.prototype.hasOwnProperty.call(t,n)&&(e[n]=t[n])},n=0;n<arguments.length;n++)t(arguments[n]);return e}},{}],dNWB:[function(e,t,n){\"use strict\";var i=s(e(\"./utils/inject-scripts\")),r=s(e(\"./utils/shallow-merge.js\"));function s(e){return e&&e.__esModule?e:{default:e}}function o(e,t){for(var n=0;n<t.length;n++){var i=t[n];i.enumerable=i.enumerable||!1,i.configurable=!0,\"value\"in i&&(i.writable=!0),Object.defineProperty(e,i.key,i)}}function a(e,t,n){return t&&o(e.prototype,t),n&&o(e,n),e}function c(e,t){if(!(e instanceof t))throw new TypeError(\"Cannot call a class as a function\")}!function(e){var t=window.performance,n=function(e,n){return!t||\"Start\"===e&&null!==this.fromMetric||t[n](this.id+\"-\"+e),this},s=function e(i){var s=this;c(this,e),this.id=(new Date).getTime()+\"-\"+t.now()+\"-\"+Math.random(),this.duration=i.duration||0===i.duration?i.duration:null,this.fromMetric=i.fromMetric||null,this.logName=i.logName||null,this.meta=(0,r.default)(i.meta)||{},this.scheduleType=i.scheduleType||\"immediately\",this.startTime=i.startTime||null,this.useEarliestStartMark=i.useEarliestStartMark||!0,this.startMarkName=this.fromMetric&&\"timeOrigin\"!==this.fromMetric?\"\".concat(this.fromMetric+\"-Start\"):\"\".concat(this.id+\"-Start\"),this.endMarkName=this.id+\"-End\",this.isActive=!0,[\"Start\",\"End\"].forEach((function(e){s[\"mark\"+e]=n.bind(s,e,\"mark\"),s[\"clear\"+e]=n.bind(s,e,\"clearMarks\")})),this.clearMeasurements=function(){[\"Start\",\"End\"].forEach((function(e){return s[\"clear\"+e].call(s)}))},this.assignMeta=function(e){return s.meta=(0,r.default)(s.meta,e),s.meta},this.calculateDuration=this.getPayload=this.remove=function(){return s},this.send=function(){return s.isActive=!1,s}},o=function(){function n(){c(this,n),this.config={},this.userContext={},this.isActiveBrowserTab=\"visible\"===document.visibilityState,this._events={},this._eventsToTrackOnce={}}return a(n,[{key:\"getEventById\",value:function(e){return this._events[e]||null}},{key:\"initialize\",value:function(e,t){this.config=e,this.setContext(t)}},{key:\"removeEventById\",value:function(){}},{key:\"sendEvents\",value:function(e){for(var t in this._events)Object.prototype.hasOwnProperty.call(this._events,t)&&(this._events[t].scheduleType===e||\"immediately\"===this._events[t].scheduleType)&&this._events[t].isActive&&this._events[t].send()}},{key:\"setContext\",value:function(e){this.userContext=(0,r.default)(this.userContext,e)}},{key:\"setCurrentRoute\",value:function(e,t){this.currentRouteName=e,this.currentRouteURL=t}},{key:\"trackEvent\",value:function(e){var t=new s(e);return this._events[t.id]=t,t}},{key:\"trackEventOnce\",value:function(e,t){if(!this._eventsToTrackOnce[e]){if(void 0===t)return null;var n=!1!==t.shouldPersist;t.logName=t.logName||e,this._eventsToTrackOnce[e]=this.trackEvent(t),this._eventsToTrackOnce[e].trackOnceLogName=e,this._eventsToTrackOnce[e].shouldPersist=n,n||(this._eventsToTrackOnce[e].send=function(){var t=this._eventsToTrackOnce[e];return t.isActive=!1,delete this._eventsToTrackOnce[e],t}.bind(this,e))}return this._eventsToTrackOnce[e]}},{key:\"injectAnalyticsCollector\",value:function(e){var t=e.cdnDomain?e.cdnDomain:\"https://fe-perf-assets.freshworks.com\";return e.src=t+\"/v2/analytics-2.0.0-beta.15.js\",(0,i.default)(e),!0}},{key:\"isAnalyticsLite\",get:function(){return!0}},{key:\"isAnalyticsEnabled\",get:function(){return!(!t||!e)}}]),n}();if(!window.FW_RUM){var u=new o;e.shouldAutoLoadAnalytics=!(\"shouldAutoLoadAnalytics\"in e)||e.shouldAutoLoadAnalytics,u.config=e,window.FW_RUM=u,window.ANALYTICS_INTERFACE_HISTORY_LENGTH=history.length;var l={preloadData:{},preloadAssets:{},cssAssets:{},vendorScript:{},frontendScript:{},primaryScript:{},secondaryScript:{},htmlParsing:{fromMetric:\"timeOrigin\"}};Object.keys(l).map((function(e){return u.trackEventOnce(e,l[e])})),e.shouldAutoLoadAnalytics&&document.addEventListener(\"DOMContentLoaded\",(function(){window.FW_RUM.injectAnalyticsCollector({defer:!0})}),{once:!0}),window.addEventListener(\"visibilitychange\",(function(){\"visible\"===document.visibilityState&&0===t.getEntriesByName(\"PerformanceTracking:FirstTabFocusEnd\").length&&t.mark(\"PerformanceTracking:FirstTabFocusEnd\")}))}}({scheduler:{metricsAdapters:[{name:\"trigmetry\",options:{endpoint:\"https://rum.haystack.es/freshid/analytics\",authToken:\"121db32190fbe328d284ee40d2521506\",schedulable:!0}}]}})},{\"./utils/inject-scripts\":\"b2lR\",\"./utils/shallow-merge.js\":\"ZV6f\"}]},{},[\"dNWB\"])</script><script defer=\"defer\" src=\"https://dash.freshworks.com/us/static/js/main.c65375ff.js\"></script><link href=\"https://dash.freshworks.com/us/static/css/main.2342a4dd.css\" rel=\"stylesheet\"></head><body><div id=\"freshworks-products-sidebar-container\"></div><div id=\"freshworks-product-promote-container\"></div><div id=\"freshworks-overlay-background\"></div><noscript>You need to enable JavaScript to run this app.</noscript><div id=\"root\"></div></body></html>'},\n",
       "  'pipeline': 'fs_kb_web_crawl_pipeline'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ede0926-2835-421b-9d81-f364cffa9f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulk ingest into Elasticsearch\n",
    "if documents:\n",
    "    success, failed = bulk(es, documents)\n",
    "    print(f\"Successfully ingested {success} documents.\")\n",
    "    if failed:\n",
    "        print(f\"Failed to ingest {failed} documents.\")\n",
    "else:\n",
    "    print(\"No documents to ingest.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26039a6-967b-4cd9-9731-2e07f469ac06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71152f6f-517b-4d8a-99c7-2d5c6d6d40e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elastic_enterprise_search import AppSearch\n",
    "import time\n",
    "\n",
    "# Connect to Elastic App Search\n",
    "app_search_url = \"http://localhost:3002\"  # Change to your App Search URL\n",
    "api_key = \"YOUR_API_KEY\"  # Replace with your API Key\n",
    "client = AppSearch(app_search_url, bearer_auth=api_key)\n",
    "\n",
    "\"https://ibm_cloud_0b9024c7_cbb7_4a9b_85d8_b10002602b8b:e24967c05fafe955711c7b783c4f647cb16f02f157fd71cd4393835d0c6e82cd@1cfae122-8d99-40f8-b662-2f582f6bead9.c5kmhkid0ujpmrucb800.databases.appdomain.cloud:31244\"\n",
    "\n",
    "# Set the engine name for storing the crawled data\n",
    "engine_name = \"web_crawl_engine\"\n",
    "\n",
    "\n",
    "https://c5kmhkid0ujpmrucb800.databases.appdomain.cloud:31244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06092f2-bf97-40e9-a798-64f7d33d8aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f85e7f-b981-49b1-9ec0-e596ae0e6ff0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AppSearch' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AppSearch' object has no attribute 'info'"
     ]
    }
   ],
   "source": [
    "client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6256e35-e44f-4b11-9049-bee139a45332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating engine: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7fb9d08a4fa0>: Failed to establish a new connection: [Errno 61] Connection refused))\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create the engine if it doesnâ€™t exist\n",
    "try:\n",
    "    client.create_engine(engine_name=engine_name, language=\"en\")  # Specify language if needed\n",
    "    print(f\"Engine '{engine_name}' created.\")\n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e):\n",
    "        print(f\"Engine '{engine_name}' already exists.\")\n",
    "    else:\n",
    "        print(f\"Error creating engine: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317e7867-930d-4cd8-87f4-c8e70d0d5934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Configure the web crawler\n",
    "domain_url = \"https://example.com\"  # Replace with the target domain\n",
    "try:\n",
    "    client.add_crawler_domain(engine_name, {\n",
    "        \"name\": domain_url,\n",
    "        \"seed_urls\": [domain_url],\n",
    "        \"crawl_rules\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"policy\": \"allow\",\n",
    "                \"rule\": \".*\",  # Crawl all URLs\n",
    "            }\n",
    "        ],\n",
    "        \"sitemap_urls\": [],  # Add sitemap URLs if available\n",
    "        \"entry_points\": [\"/\"]  # Start from the home page\n",
    "    })\n",
    "    print(f\"Domain '{domain_url}' added to the engine.\")\n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e):\n",
    "        print(f\"Domain '{domain_url}' already exists in the engine.\")\n",
    "    else:\n",
    "        print(f\"Error adding domain: {e}\")\n",
    "\n",
    "# Step 3: Start the crawler\n",
    "try:\n",
    "    crawl_request = client.start_crawler(engine_name)\n",
    "    crawl_request_id = crawl_request[\"id\"]\n",
    "    print(f\"Started crawl with request ID: {crawl_request_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error starting crawler: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Step 4: Monitor the crawl job status\n",
    "print(\"Monitoring crawl status...\")\n",
    "while True:\n",
    "    status = client.get_crawler_crawl_request(engine_name, crawl_request_id)[\"status\"]\n",
    "    if status == \"complete\":\n",
    "        print(\"Crawl completed successfully.\")\n",
    "        break\n",
    "    elif status == \"failed\":\n",
    "        print(\"Crawl failed.\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Crawl in progress... Current status: {status}\")\n",
    "    time.sleep(10)  # Poll every 10 seconds\n",
    "\n",
    "# Step 5: Fetch and display documents from the index\n",
    "try:\n",
    "    documents = client.list_documents(engine_name)\n",
    "    for doc in documents[\"results\"]:\n",
    "        print(f\"Title: {doc['title']}\\nURL: {doc['url']}\\nContent: {doc['body_content'][:200]}...\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving documents: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b41ce45-84ce-460b-94ed-b388766f0c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
